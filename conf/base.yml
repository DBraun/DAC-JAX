# Model setup
DAC.sample_rate: 44100
DAC.encoder_dim: 64
DAC.encoder_rates: [2, 4, 8, 8]
DAC.decoder_dim: 1536
DAC.decoder_rates: [8, 8, 4, 2]

# Quantization
DAC.n_codebooks: 9
DAC.codebook_size: 1024
DAC.codebook_dim: 8
DAC.quantizer_dropout: 1.0  # bool

# Discriminator
Discriminator.sample_rate: 44100
Discriminator.rates: []
Discriminator.periods: [2, 3, 5, 7, 11]
Discriminator.fft_sizes: [2048, 1024, 512]
Discriminator.bands:
  - [0.0, 0.1]
  - [0.1, 0.25]
  - [0.25, 0.5]
  - [0.5, 0.75]
  - [0.75, 1.0]

# Optimization
create_generator_scheduler.learning_rate: 1e-4
create_generator_scheduler.lr_gamma: 0.999996

create_generator_optimizer.adam_b1: 0.8
create_generator_optimizer.adam_b2: 0.99
create_generator_optimizer.learning_rate: 1e-4

create_discriminator_scheduler.learning_rate: 1e-4
create_discriminator_scheduler.lr_gamma: 0.999996

create_discriminator_optimizer.adam_b1: 0.8
create_discriminator_optimizer.adam_b2: 0.99
create_discriminator_optimizer.learning_rate: 1e-4

lambdas:
  mel/loss: 15.0
  adv/feat_loss: 2.0
  adv/gen_loss: 1.0
  vq/commitment_loss: 0.25
  vq/codebook_loss: 1.0

train.batch_size: 72
train.val_batch_size: 100
train.num_iterations: 250000
train.valid_freq: 1000
train.sample_freq: 10000
train.early_stop_patience: 4
train.ckpt_max_keep: 4
train.seed: 0
train.tabulate: 0

log_training.log_every_steps: 10

# Loss setup
multiscale_stft_loss.window_lengths: [2048, 512]

mel_spectrogram_loss.n_mels: [5, 10, 20, 40, 80, 160, 320]
mel_spectrogram_loss.window_lengths: [32, 64, 128, 256, 512, 1024, 2048]
mel_spectrogram_loss.lower_edge_hz: [0, 0, 0, 0, 0, 0, 0]
mel_spectrogram_loss.upper_edge_hz: [null, null, null, null, null, null, null]
mel_spectrogram_loss.pow: 1.0
mel_spectrogram_loss.clamp_eps: 1.0e-5
mel_spectrogram_loss.mag_weight: 0.0

# Data Augmentation
VolumeTransform.enabled: 1
VolumeTransform.min_db: -16
VolumeTransform.max_db: -16
SwapStereoAudioTransform.p: 0.1
InvertPhaseAudioTransform.p: 0.1

# Data
train/SaliencyParams.enabled: 0
train/SaliencyParams.num_tries: 8
train/SaliencyParams.loudness_cutoff: -40

# Data
train/create_dataset.duration: 0.38
train/create_dataset.sources:
  speech_fb:
    - /data/daps/train
  speech_hq:
    - /data/vctk
    - /data/vocalset
    - /data/read_speech
    - /data/french_speech
  speech_uq:
    - /data/emotional_speech/
    - /data/common_voice/
    - /data/german_speech/
    - /data/russian_speech/
    - /data/spanish_speech/
  music_hq:
    - /data/musdb/train
  music_uq:
    - /data/jamendo
  general:
    - /data/audioset/data/unbalanced_train_segments/
    - /data/audioset/data/balanced_train_segments/

val/create_dataset.duration: 5.0
val/create_dataset.sources:
  speech_hq:
    - /data/daps/val
  music_hq:
    - /data/musdb/test
  general:
    - /data/audioset/data/eval_segments/

test/create_dataset.duration: 10.0
test/create_dataset.sources:
  speech_hq:
    - /data/daps/test
  music_hq:
    - /data/musdb/test
  general:
    - /data/audioset/data/eval_segments/
